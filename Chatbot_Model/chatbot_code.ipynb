{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13808,"sourceType":"datasetVersion","datasetId":9714},{"sourceId":18178,"sourceType":"datasetVersion","datasetId":13433}],"dockerImageVersionId":29962,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-08T17:01:45.933671Z","iopub.execute_input":"2024-07-08T17:01:45.934075Z","iopub.status.idle":"2024-07-08T17:01:45.938717Z","shell.execute_reply.started":"2024-07-08T17:01:45.934038Z","shell.execute_reply":"2024-07-08T17:01:45.937714Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Attention Class","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nfrom tensorflow.python.keras.layers import Layer\nfrom tensorflow.python.keras import backend as K\n\n\nclass AttentionLayer(Layer):\n    \"\"\"\n    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n    There are three sets of weights introduced W_a, U_a, and V_a\n     \"\"\"\n\n    def __init__(self, **kwargs):\n        super(AttentionLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert isinstance(input_shape, list)\n        # Create a trainable weight variable for this layer.\n\n        self.W_a = self.add_weight(name='W_a',\n                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n                                   initializer='uniform',\n                                   trainable=True)\n        self.U_a = self.add_weight(name='U_a',\n                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n                                   initializer='uniform',\n                                   trainable=True)\n        self.V_a = self.add_weight(name='V_a',\n                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n                                   initializer='uniform',\n                                   trainable=True)\n\n        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n\n    def call(self, inputs, verbose=False):\n        \"\"\"\n        inputs: [encoder_output_sequence, decoder_output_sequence]\n        \"\"\"\n        assert type(inputs) == list\n        encoder_out_seq, decoder_out_seq = inputs\n        if verbose:\n            print('encoder_out_seq>', encoder_out_seq.shape)\n            print('decoder_out_seq>', decoder_out_seq.shape)\n\n        def energy_step(inputs, states):\n            \"\"\" Step function for computing energy for a single decoder state\n            inputs: (batchsize * 1 * de_in_dim)\n            states: (batchsize * 1 * de_latent_dim)\n            \"\"\"\n\n            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n\n            \"\"\" Some parameters required for shaping tensors\"\"\"\n            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n            de_hidden = inputs.shape[-1]\n\n            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n            # <= batch size * en_seq_len * latent_dim\n            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n\n            \"\"\" Computing hj.Ua \"\"\"\n            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n            if verbose:\n                print('Ua.h>', U_a_dot_h.shape)\n\n            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n            # <= batch_size*en_seq_len, latent_dim\n            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n            if verbose:\n                print('Ws+Uh>', Ws_plus_Uh.shape)\n\n            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n            # <= batch_size, en_seq_len\n            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n            # <= batch_size, en_seq_len\n            e_i = K.softmax(e_i)\n\n            if verbose:\n                print('ei>', e_i.shape)\n\n            return e_i, [e_i]\n\n        def context_step(inputs, states):\n            \"\"\" Step function for computing ci using ei \"\"\"\n\n            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n\n            # <= batch_size, hidden_size\n            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n            if verbose:\n                print('ci>', c_i.shape)\n            return c_i, [c_i]\n\n        fake_state_c = K.sum(encoder_out_seq, axis=1)\n        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n\n        \"\"\" Computing energy outputs \"\"\"\n        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n        last_out, e_outputs, _ = K.rnn(\n            energy_step, decoder_out_seq, [fake_state_e],\n        )\n\n        \"\"\" Computing context vectors \"\"\"\n        last_out, c_outputs, _ = K.rnn(\n            context_step, e_outputs, [fake_state_c],\n        )\n\n        return c_outputs, e_outputs\n\n    def compute_output_shape(self, input_shape):\n        \"\"\" Outputs produced by the layer \"\"\"\n        return [\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n        ]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:01:57.752028Z","iopub.execute_input":"2024-07-08T17:01:57.752410Z","iopub.status.idle":"2024-07-08T17:01:57.779693Z","shell.execute_reply.started":"2024-07-08T17:01:57.752368Z","shell.execute_reply":"2024-07-08T17:01:57.778470Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import re\n\nlines = open('../input/chatbot-data/cornell movie-dialogs corpus/movie_lines.txt', encoding='utf-8',\n             errors='ignore').read().split('\\n')\n\nconvers = open('../input/chatbot-data/cornell movie-dialogs corpus/movie_conversations.txt', encoding='utf-8',\n             errors='ignore').read().split('\\n')\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2024-07-08T17:01:58.224932Z","iopub.execute_input":"2024-07-08T17:01:58.225426Z","iopub.status.idle":"2024-07-08T17:01:58.860730Z","shell.execute_reply.started":"2024-07-08T17:01:58.225383Z","shell.execute_reply":"2024-07-08T17:01:58.859454Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"len(lines)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:01:58.862734Z","iopub.execute_input":"2024-07-08T17:01:58.863122Z","iopub.status.idle":"2024-07-08T17:01:58.870844Z","shell.execute_reply.started":"2024-07-08T17:01:58.863085Z","shell.execute_reply":"2024-07-08T17:01:58.869657Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"304714"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Preprocess","metadata":{}},{"cell_type":"code","source":"\nexchn = []\nfor conver in convers:\n    exchn.append(conver.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \" \").replace(\",\",\"\").split())\n\ndiag = {}\nfor line in lines:\n    diag[line.split(' +++$+++ ')[0]] = line.split(' +++$+++ ')[-1]\n\n\n\n## delete\ndel(lines, convers, conver, line)\n\n\n\nquestions = []\nanswers = []\n\nfor conver in exchn:\n    for i in range(len(conver) - 1):\n        questions.append(diag[conver[i]])\n        answers.append(diag[conver[i+1]])\n        \n        \n        \n\n## delete\ndel(diag, exchn, conver, i)\n\n\n###############################\n#        max_len = 13         #\n###############################\n\nsorted_ques = []\nsorted_ans = []\nfor i in range(len(questions)):\n    if len(questions[i]) < 13:\n        sorted_ques.append(questions[i])\n        sorted_ans.append(answers[i])\n\n\n\n###############################\n#                             #\n###############################\n\n\n\n\ndef clean_text(txt):\n    txt = txt.lower()\n    txt = re.sub(r\"i'm\", \"i am\", txt)\n    txt = re.sub(r\"he's\", \"he is\", txt)\n    txt = re.sub(r\"she's\", \"she is\", txt)\n    txt = re.sub(r\"that's\", \"that is\", txt)\n    txt = re.sub(r\"what's\", \"what is\", txt)\n    txt = re.sub(r\"where's\", \"where is\", txt)\n    txt = re.sub(r\"\\'ll\", \" will\", txt)\n    txt = re.sub(r\"\\'ve\", \" have\", txt)\n    txt = re.sub(r\"\\'re\", \" are\", txt)\n    txt = re.sub(r\"\\'d\", \" would\", txt)\n    txt = re.sub(r\"won't\", \"will not\", txt)\n    txt = re.sub(r\"can't\", \"can not\", txt)\n    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n    return txt\n\nclean_ques = []\nclean_ans = []\n\nfor line in sorted_ques:\n    clean_ques.append(clean_text(line))\n        \nfor line in sorted_ans:\n    clean_ans.append(clean_text(line))\n\n\n\n## delete\ndel(answers, questions, line)\n\n\n###############################\n#                             #\n###############################\n\n\nfor i in range(len(clean_ans)):\n    clean_ans[i] = ' '.join(clean_ans[i].split()[:11])\n\n\n\n###############################\n#                             #\n###############################\n\ndel(sorted_ans, sorted_ques)\n\n\n## trimming\nclean_ans=clean_ans[:30000]\nclean_ques=clean_ques[:30000]\n## delete\n\n\n###  count occurences ###\nword2count = {}\n\nfor line in clean_ques:\n    for word in line.split():\n        if word not in word2count:\n            word2count[word] = 1\n        else:\n            word2count[word] += 1\nfor line in clean_ans:\n    for word in line.split():\n        if word not in word2count:\n            word2count[word] = 1\n        else:\n            word2count[word] += 1\n\n## delete\ndel(word, line)\n\n\n###  remove less frequent ###\nthresh = 5\n\nvocab = {}\nword_num = 0\nfor word, count in word2count.items():\n    if count >= thresh:\n        vocab[word] = word_num\n        word_num += 1\n        \n## delete\ndel(word2count, word, count, thresh)       \ndel(word_num)        \n\n\n\nfor i in range(len(clean_ans)):\n    clean_ans[i] = '<SOS> ' + clean_ans[i] + ' <EOS>'\n\n\n\ntokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\nx = len(vocab)\nfor token in tokens:\n    vocab[token] = x\n    x += 1\n    \n    \n\nvocab['cameron'] = vocab['<PAD>']\nvocab['<PAD>'] = 0\n\n## delete\ndel(token, tokens) \ndel(x)\n\n### inv answers dict ###\ninv_vocab = {w:v for v, w in vocab.items()}\n\n\n\n## delete\ndel(i)\n\n\n\nencoder_inp = []\nfor line in clean_ques:\n    lst = []\n    for word in line.split():\n        if word not in vocab:\n            lst.append(vocab['<OUT>'])\n        else:\n            lst.append(vocab[word])\n        \n    encoder_inp.append(lst)\n\ndecoder_inp = []\nfor line in clean_ans:\n    lst = []\n    for word in line.split():\n        if word not in vocab:\n            lst.append(vocab['<OUT>'])\n        else:\n            lst.append(vocab[word])        \n    decoder_inp.append(lst)\n\n### delete\ndel(clean_ans, clean_ques, line, lst, word)\n\n\n\n\n\n\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nencoder_inp = pad_sequences(encoder_inp, 13, padding='post', truncating='post')\ndecoder_inp = pad_sequences(decoder_inp, 13, padding='post', truncating='post')\n\n\n\n\ndecoder_final_output = []\nfor i in decoder_inp:\n    decoder_final_output.append(i[1:]) \n\ndecoder_final_output = pad_sequences(decoder_final_output, 13, padding='post', truncating='post')\n\n\ndel(i)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:01:59.296062Z","iopub.execute_input":"2024-07-08T17:01:59.296495Z","iopub.status.idle":"2024-07-08T17:02:02.399452Z","shell.execute_reply.started":"2024-07-08T17:01:59.296458Z","shell.execute_reply":"2024-07-08T17:02:02.398433Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# decoder_final_output, decoder_final_input, encoder_final, vocab, inv_vocab\n\nVOCAB_SIZE = len(vocab)\nMAX_LEN = 13\n\nprint(decoder_final_output.shape, decoder_inp.shape, encoder_inp.shape, len(vocab), len(inv_vocab), inv_vocab[0])","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:02:02.402008Z","iopub.execute_input":"2024-07-08T17:02:02.402481Z","iopub.status.idle":"2024-07-08T17:02:02.409622Z","shell.execute_reply.started":"2024-07-08T17:02:02.402432Z","shell.execute_reply":"2024-07-08T17:02:02.408515Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(30000, 13) (30000, 13) (30000, 13) 3027 3027 <PAD>\n","output_type":"stream"}]},{"cell_type":"code","source":"inv_vocab[16]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:02:02.411077Z","iopub.execute_input":"2024-07-08T17:02:02.411408Z","iopub.status.idle":"2024-07-08T17:02:02.429426Z","shell.execute_reply.started":"2024-07-08T17:02:02.411375Z","shell.execute_reply":"2024-07-08T17:02:02.428313Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'they'"},"metadata":{}}]},{"cell_type":"code","source":"#print(len(decoder_final_input), MAX_LEN, VOCAB_SIZE)\n#decoder_final_input[0]\n#decoder_output_data = np.zeros((len(decoder_final_input), MAX_LEN, VOCAB_SIZE), dtype=\"float32\")\n#print(decoder_output_data.shape)\n#decoder_final_input[80]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:02:02.430733Z","iopub.execute_input":"2024-07-08T17:02:02.431066Z","iopub.status.idle":"2024-07-08T17:02:02.441865Z","shell.execute_reply.started":"2024-07-08T17:02:02.431036Z","shell.execute_reply":"2024-07-08T17:02:02.440668Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\ndecoder_final_output = to_categorical(decoder_final_output, len(vocab))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:02:02.445151Z","iopub.execute_input":"2024-07-08T17:02:02.445506Z","iopub.status.idle":"2024-07-08T17:02:03.536749Z","shell.execute_reply.started":"2024-07-08T17:02:02.445475Z","shell.execute_reply":"2024-07-08T17:02:03.535454Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"decoder_final_output.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:02:03.538779Z","iopub.execute_input":"2024-07-08T17:02:03.539117Z","iopub.status.idle":"2024-07-08T17:02:03.544961Z","shell.execute_reply.started":"2024-07-08T17:02:03.539075Z","shell.execute_reply":"2024-07-08T17:02:03.543844Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(30000, 13, 3027)"},"metadata":{}}]},{"cell_type":"code","source":"pip show tensorflow ","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:06:52.623009Z","iopub.execute_input":"2024-07-08T17:06:52.623385Z","iopub.status.idle":"2024-07-08T17:06:59.696861Z","shell.execute_reply.started":"2024-07-08T17:06:52.623353Z","shell.execute_reply":"2024-07-08T17:06:59.695501Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Name: tensorflow\nVersion: 2.2.0\nSummary: TensorFlow is an open source machine learning framework for everyone.\nHome-page: https://www.tensorflow.org/\nAuthor: Google Inc.\nAuthor-email: packages@tensorflow.org\nLicense: Apache 2.0\nLocation: /opt/conda/lib/python3.7/site-packages\nRequires: numpy, h5py, absl-py, protobuf, six, grpcio, gast, keras-preprocessing, astunparse, wrapt, opt-einsum, scipy, wheel, tensorboard, termcolor, tensorflow-estimator, google-pasta\nRequired-by: Keras, fancyimpute\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Glove Embedding","metadata":{}},{"cell_type":"code","source":"\nembeddings_index = {}\nwith open('../input/glove6b50d/glove.6B.50d.txt', encoding='utf-8') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs\n    f.close()\n\nprint(\"Glove Loded!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:02:03.546429Z","iopub.execute_input":"2024-07-08T17:02:03.546797Z","iopub.status.idle":"2024-07-08T17:02:11.432356Z","shell.execute_reply.started":"2024-07-08T17:02:03.546758Z","shell.execute_reply":"2024-07-08T17:02:11.431070Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Glove Loded!\n","output_type":"stream"}]},{"cell_type":"code","source":"\nembedding_dimention = 50\ndef embedding_matrix_creater(embedding_dimention, word_index):\n    embedding_matrix = np.zeros((len(word_index)+1, embedding_dimention))\n    for word, i in word_index.items():\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n          # words not found in embedding index will be all-zeros.\n            embedding_matrix[i] = embedding_vector\n    return embedding_matrix\nembedding_matrix = embedding_matrix_creater(50, word_index=vocab)    \n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:02:11.433662Z","iopub.execute_input":"2024-07-08T17:02:11.433996Z","iopub.status.idle":"2024-07-08T17:02:11.448005Z","shell.execute_reply.started":"2024-07-08T17:02:11.433962Z","shell.execute_reply":"2024-07-08T17:02:11.447007Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"del(embeddings_index)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:02:11.449756Z","iopub.execute_input":"2024-07-08T17:02:11.450132Z","iopub.status.idle":"2024-07-08T17:02:11.529397Z","shell.execute_reply.started":"2024-07-08T17:02:11.450096Z","shell.execute_reply":"2024-07-08T17:02:11.528334Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"embedding_matrix.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:02:11.550100Z","iopub.execute_input":"2024-07-08T17:02:11.550592Z","iopub.status.idle":"2024-07-08T17:02:11.557421Z","shell.execute_reply.started":"2024-07-08T17:02:11.550549Z","shell.execute_reply":"2024-07-08T17:02:11.556170Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(3028, 50)"},"metadata":{}}]},{"cell_type":"code","source":"embedding_matrix[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:02:11.559003Z","iopub.execute_input":"2024-07-08T17:02:11.559357Z","iopub.status.idle":"2024-07-08T17:02:11.572196Z","shell.execute_reply.started":"2024-07-08T17:02:11.559314Z","shell.execute_reply":"2024-07-08T17:02:11.571066Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM, Input, Bidirectional, Concatenate, Dropout, Attention","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:02:11.573843Z","iopub.execute_input":"2024-07-08T17:02:11.574243Z","iopub.status.idle":"2024-07-08T17:02:11.586523Z","shell.execute_reply.started":"2024-07-08T17:02:11.574203Z","shell.execute_reply":"2024-07-08T17:02:11.585180Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"embed = Embedding(VOCAB_SIZE+1, \n                  50, \n                  \n                  input_length=13,\n                  trainable=True)\n\nembed.build((None,))\nembed.set_weights([embedding_matrix])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:02:11.588617Z","iopub.execute_input":"2024-07-08T17:02:11.589122Z","iopub.status.idle":"2024-07-08T17:02:11.685716Z","shell.execute_reply.started":"2024-07-08T17:02:11.589070Z","shell.execute_reply":"2024-07-08T17:02:11.684601Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"enc_inp = Input(shape=(13, ))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:02:11.688506Z","iopub.execute_input":"2024-07-08T17:02:11.688849Z","iopub.status.idle":"2024-07-08T17:02:11.699419Z","shell.execute_reply.started":"2024-07-08T17:02:11.688812Z","shell.execute_reply":"2024-07-08T17:02:11.698058Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"Installed TensorFlow version:\", tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:18:16.618186Z","iopub.execute_input":"2024-07-08T17:18:16.618643Z","iopub.status.idle":"2024-07-08T17:18:16.624756Z","shell.execute_reply.started":"2024-07-08T17:18:16.618599Z","shell.execute_reply":"2024-07-08T17:18:16.623769Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Installed TensorFlow version: 2.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"print(enc_inp)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:02:11.701231Z","iopub.execute_input":"2024-07-08T17:02:11.701699Z","iopub.status.idle":"2024-07-08T17:02:11.711080Z","shell.execute_reply.started":"2024-07-08T17:02:11.701660Z","shell.execute_reply":"2024-07-08T17:02:11.709633Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Tensor(\"input_1:0\", shape=(None, 13), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"#embed = Embedding(VOCAB_SIZE+1, 50, mask_zero=True, input_length=13)(enc_inp)\nenc_embed = embed(enc_inp)\nenc_lstm = Bidirectional(LSTM(400, return_state=True, dropout=0.05, return_sequences = True))\n\nencoder_outputs, forward_h, forward_c, backward_h, backward_c = enc_lstm(enc_embed)\n\nstate_h = Concatenate()([forward_h, backward_h])\nstate_c = Concatenate()([forward_c, backward_c])\n\nenc_states = [state_h, state_c]\n\n\ndec_inp = Input(shape=(13, ))\ndec_embed = embed(dec_inp)\ndec_lstm = LSTM(400*2, return_state=True, return_sequences=True, dropout=0.05)\noutput, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n\n# attention\nattn_layer = AttentionLayer()\nattn_op, attn_state = attn_layer([encoder_outputs, output])\ndecoder_concat_input = Concatenate(axis=-1)([output, attn_op])\n\n\ndec_dense = Dense(VOCAB_SIZE, activation='softmax')\nfinal_output = dec_dense(decoder_concat_input)\n\nmodel = Model([enc_inp, dec_inp], final_output)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:02:11.713367Z","iopub.execute_input":"2024-07-08T17:02:11.713808Z","iopub.status.idle":"2024-07-08T17:02:14.419140Z","shell.execute_reply.started":"2024-07-08T17:02:11.713765Z","shell.execute_reply":"2024-07-08T17:02:14.418035Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            [(None, 13)]         0                                            \n__________________________________________________________________________________________________\ninput_1 (InputLayer)            [(None, 13)]         0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, 13, 50)       151400      input_1[0][0]                    \n                                                                 input_2[0][0]                    \n__________________________________________________________________________________________________\nbidirectional (Bidirectional)   [(None, 13, 800), (N 1443200     embedding[0][0]                  \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 800)          0           bidirectional[0][1]              \n                                                                 bidirectional[0][3]              \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 800)          0           bidirectional[0][2]              \n                                                                 bidirectional[0][4]              \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   [(None, 13, 800), (N 2723200     embedding[1][0]                  \n                                                                 concatenate[0][0]                \n                                                                 concatenate_1[0][0]              \n__________________________________________________________________________________________________\nattention_layer (AttentionLayer ((None, 13, 800), (N 1280800     bidirectional[0][0]              \n                                                                 lstm_1[0][0]                     \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 13, 1600)     0           lstm_1[0][0]                     \n                                                                 attention_layer[0][0]            \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 13, 3027)     4846227     concatenate_2[0][0]              \n==================================================================================================\nTotal params: 10,444,827\nTrainable params: 10,444,827\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"import keras\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-07-07T12:23:49.963617Z","iopub.execute_input":"2024-07-07T12:23:49.964028Z","iopub.status.idle":"2024-07-07T12:23:50.043616Z","shell.execute_reply.started":"2024-07-07T12:23:49.963984Z","shell.execute_reply":"2024-07-07T12:23:50.042550Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2024-07-07T12:23:50.045513Z","iopub.execute_input":"2024-07-07T12:23:50.045952Z","iopub.status.idle":"2024-07-07T12:23:50.063611Z","shell.execute_reply.started":"2024-07-07T12:23:50.045906Z","shell.execute_reply":"2024-07-07T12:23:50.062403Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model.fit([encoder_inp, decoder_inp], decoder_final_output, epochs=10, batch_size=24, validation_split=0.15)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T12:23:50.065185Z","iopub.execute_input":"2024-07-07T12:23:50.065562Z","iopub.status.idle":"2024-07-07T13:46:42.369265Z","shell.execute_reply.started":"2024-07-07T12:23:50.065526Z","shell.execute_reply":"2024-07-07T13:46:42.367563Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1/10\n1063/1063 [==============================] - 494s 465ms/step - loss: 2.8935 - acc: 0.5142 - val_loss: 2.6693 - val_acc: 0.5352\nEpoch 2/10\n1063/1063 [==============================] - 497s 468ms/step - loss: 2.5371 - acc: 0.5431 - val_loss: 2.5741 - val_acc: 0.5443\nEpoch 3/10\n1063/1063 [==============================] - 496s 466ms/step - loss: 2.3810 - acc: 0.5521 - val_loss: 2.5518 - val_acc: 0.5492\nEpoch 4/10\n1063/1063 [==============================] - 495s 466ms/step - loss: 2.2249 - acc: 0.5603 - val_loss: 2.5691 - val_acc: 0.5484\nEpoch 5/10\n1063/1063 [==============================] - 496s 467ms/step - loss: 2.0558 - acc: 0.5718 - val_loss: 2.6138 - val_acc: 0.5484\nEpoch 6/10\n1063/1063 [==============================] - 494s 465ms/step - loss: 1.8741 - acc: 0.5894 - val_loss: 2.6829 - val_acc: 0.5458\nEpoch 7/10\n1063/1063 [==============================] - 492s 463ms/step - loss: 1.6902 - acc: 0.6161 - val_loss: 2.7585 - val_acc: 0.5412\nEpoch 8/10\n1063/1063 [==============================] - 496s 467ms/step - loss: 1.5148 - acc: 0.6468 - val_loss: 2.8332 - val_acc: 0.5366\nEpoch 9/10\n1063/1063 [==============================] - 493s 464ms/step - loss: 1.3524 - acc: 0.6784 - val_loss: 2.9208 - val_acc: 0.5345\nEpoch 10/10\n1063/1063 [==============================] - 494s 465ms/step - loss: 1.2068 - acc: 0.7110 - val_loss: 3.0135 - val_acc: 0.5295\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7d43bf83a390>"},"metadata":{}}]},{"cell_type":"markdown","source":"# inferece","metadata":{}},{"cell_type":"code","source":"model.save('chatbot.h5')\nmodel.save_weights('chatbot_weights.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Attention Inference\n","metadata":{}},{"cell_type":"code","source":"enc_model = tf.keras.models.Model(enc_inp, [encoder_outputs, enc_states])\n\n\ndecoder_state_input_h = tf.keras.layers.Input(shape=( 400 * 2,))\ndecoder_state_input_c = tf.keras.layers.Input(shape=( 400 * 2,))\n\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\n\ndecoder_outputs, state_h, state_c = dec_lstm(dec_embed , initial_state=decoder_states_inputs)\n\n\ndecoder_states = [state_h, state_c]\n\n#decoder_output = dec_dense(decoder_outputs)\n\ndec_model = tf.keras.models.Model([dec_inp, decoder_states_inputs],\n                                      [decoder_outputs] + decoder_states)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T13:46:42.711104Z","iopub.execute_input":"2024-07-07T13:46:42.711663Z","iopub.status.idle":"2024-07-07T13:46:43.024075Z","shell.execute_reply.started":"2024-07-07T13:46:42.711611Z","shell.execute_reply":"2024-07-07T13:46:43.022716Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"\nfrom keras.preprocessing.sequence import pad_sequences\nprint(\"##########################################\")\nprint(\"#       start chatting ver. 1.0          #\")\nprint(\"##########################################\")\n\n\nprepro1 = \"\"\nwhile prepro1 != 'q':\n    \n    prepro1 = input(\"you : \")\n    try:\n        prepro1 = clean_text(prepro1)\n        prepro = [prepro1]\n        \n        txt = []\n        for x in prepro:\n            lst = []\n            for y in x.split():\n                try:\n                    lst.append(vocab[y])\n                except:\n                    lst.append(vocab['<OUT>'])\n            txt.append(lst)\n        txt = pad_sequences(txt, 13, padding='post')\n\n\n        ###\n        enc_op, stat = enc_model.predict( txt )\n\n        empty_target_seq = np.zeros( ( 1 , 1) )\n        empty_target_seq[0, 0] = vocab['<SOS>']\n        stop_condition = False\n        decoded_translation = ''\n\n\n        while not stop_condition :\n\n            dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + stat )\n\n            ###\n            ###########################\n            attn_op, attn_state = attn_layer([enc_op, dec_outputs])\n            decoder_concat_input = Concatenate(axis=-1)([dec_outputs, attn_op])\n            decoder_concat_input = dec_dense(decoder_concat_input)\n            ###########################\n\n            sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n\n            sampled_word = inv_vocab[sampled_word_index] + ' '\n\n            if sampled_word != '<EOS> ':\n                decoded_translation += sampled_word           \n\n\n            if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n                stop_condition = True\n\n            empty_target_seq = np.zeros( ( 1 , 1 ) )  \n            empty_target_seq[ 0 , 0 ] = sampled_word_index\n            stat = [ h , c ] \n\n        print(\"chatbot attention : \", decoded_translation )\n        print(\"==============================================\")\n\n    except:\n        print(\"sorry didn't got you , please type again :( \")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T11:04:55.886212Z","iopub.execute_input":"2024-07-08T11:04:55.886647Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"},{"name":"stdout","text":"##########################################\n#       start chatting ver. 1.0          #\n##########################################\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"you :  yo hi\n"},{"name":"stdout","text":"sorry didn't got you , please type again :( \n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"you :  hi\n"},{"name":"stdout","text":"sorry didn't got you , please type again :( \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}